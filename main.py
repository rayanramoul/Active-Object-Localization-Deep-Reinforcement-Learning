# -*- coding: utf-8 -*-
"""BEST_PROJECT_DEEP_RL.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vbzsvdhqLR1kCz1Sr1punTTXaqyKlMP0
"""

import torchvision
#import torchvision.datasets.SBDataset as sbd
import torch
import torch.nn.functional as F
from torch.utils.data import DataLoader
import numpy as np

import torch.nn as nn
import torch.nn.parallel
import torch.backends.cudnn as cudnn
import torch.optim
import torch.utils.data
import torchvision.transforms as transforms
import torchvision.datasets as datasets
from IPython.display import clear_output


#!pip3 install torch==1.5.1 torchvision==0.6.1 -f https://download.pytorch.org/whl/cu92/torch_stable.html
try:
    if 'google.colab' in str(get_ipython()):
        from google.colab import drive
        drive.mount('/content/gdrive')
        LOAD = True
        SAVE_MODEL_PATH = '/content/gdrive/MyDrive/models/' + 'q_network'
    else:
        LOAD = False
        SAVE_MODEL_PATH = "./models/q_network"
except NameError:
        LOAD = False
        SAVE_MODEL_PATH = "./models/q_network"
batch_size = 32
PATH="./datasets/"

class CustomRotation(object):
  def __call__(self, image):
    return image.transpose(0, 2).transpose(0, 1)


class NoisySBDataset():
    def __init__(self, path, image_set="train", transforms = None, download=True):
        super().__init__()
        self.transforms = transforms
        self.dataset = torchvision.datasets.SBDataset(root=path,
                                                      image_set=image_set,
                                                      download=download)

    def __len__(self):
        return len(self.dataset)

    def __getitem__(self, idx):  # a[x] for calling a.__getitem__(x)
        img, truth = self.dataset[idx]
        if self.transforms:
            img = self.transforms(img)
        return (img, truth)


def get_transform(train):
    base_size = 520
    crop_size = 480

    min_size = int((0.5 if train else 1.0) * base_size)
    max_size = int((2.0 if train else 1.0) * base_size)
    transf = []
    transf.append( transforms.ToTensor())
    transf.append(transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                  std=[0.229, 0.224, 0.225]))
    return transforms.Compose(transf)
    
def make_image_transform(image_transform_params: dict,
                         transform: object):
    resize_image = image_transform_params['image_mode']
    if resize_image == 'none':
        preprocess_image = None
    elif resize_image == 'shrink':
        preprocess_image = transforms.Resize((image_transform_params['output_image_size']['width'],
                                              image_transform_params['output_image_size']['height']))
    elif resize_image == 'crop':
        preprocess_image = transforms.CenterCrop((image_transform_params['output_image_size']['width'],
                                                  image_transform_params['output_image_size']['height']))

    if preprocess_image is not None:
        if transform is not None:
            image_transform = transforms.Compose([preprocess_image, transform])
        else:
            image_transform = preprocess_image
    else:
        image_transform = transform
    return image_transform


def read_voc_dataset(download=True, year='2007'):
    T = transforms.Compose([
                            transforms.Resize((224, 224)),
                            transforms.ToTensor(),
                             #CustomRotation()
                            ])
    voc_data =  torchvision.datasets.VOCDetection(PATH, year=year, image_set='train', 
                        download=download, transform=T)
    train_loader = DataLoader(voc_data,shuffle=True)

    voc_val =  torchvision.datasets.VOCDetection(PATH, year=year, image_set='val', 
                        download=download, transform=T)
    val_loader = DataLoader(voc_val,shuffle=False)

    return voc_data, voc_val
    #return train_loader, val_loader

def get_images_labels(dataloader):
    data_iter = iter(dataloader)
    images, labels = next(data_iter)
    return images, labels

def read_sbd_dataset(batch_size, download=True):
    T = transforms.Compose([
                            transforms.Resize((224, 224)),
                            transforms.ToTensor()
                            ])
    voc_data =  NoisySBDataset(PATH, image_set='train', 
                        download=download, transforms=T)
    train_loader = DataLoader(voc_data, batch_size=32,shuffle=False,  collate_fn=lambda x: x)

    voc_val =  NoisySBDataset(PATH, image_set='val', 
                        download=download, transforms=T)
    val_loader = DataLoader(voc_val, batch_size=32,shuffle=False,  collate_fn=lambda x: x)

    return train_loader, val_loader

import matplotlib.pyplot as plt
import matplotlib.patches as patches
"""


for (image, ground_truth) in train_loader:
    print(ground_truth)
"""
def show_new_bdbox(image, labels, color='r'):
    xmin, xmax, ymin, ymax = labels[0],labels[1],labels[2],labels[3]
    fig,ax = plt.subplots(1)
    ax.imshow(image.transpose(0, 2).transpose(0, 1))

    width = xmax-xmin
    height = ymax-ymin
    rect = patches.Rectangle((xmin,ymin),width,height,linewidth=3,edgecolor=color,facecolor='none')

    # Add the patch to the Axes
    ax.add_patch(rect)
    plt.show()

def show_bdbox(train_loader, index):
    fig,ax = plt.subplots(1)
    img, target = train_loader[index]
    ax.imshow(img.transpose(0, 2).transpose(0, 1))
    #print("Labels : "+str(labels['annotation']['size']))
    
    print(img)
    print(target)
    xmin = ( int(target['annotation']['object'][0]['bndbox']['xmin']) /  int(target['annotation']['size']['width']) ) * 224
    xmax = ( int(target['annotation']['object'][0]['bndbox']['xmax']) /  int(target['annotation']['size']['width']) ) * 224

    ymin = ( int(target['annotation']['object'][0]['bndbox']['ymin']) /  int(target['annotation']['size']['height']) ) * 224
    ymax = ( int(target['annotation']['object'][0]['bndbox']['ymax']) /  int(target['annotation']['size']['height']) ) * 224
    
    width = xmax-xmin
    height = ymax-ymin
    rect = patches.Rectangle((xmin,ymin),width,height,linewidth=3,edgecolor='r',facecolor='none')

    # Add the patch to the Axes
    ax.add_patch(rect)
    plt.show()

def extract(index, loader):
    img, target = loader[index]
    xmin = ( int(target['annotation']['object'][0]['bndbox']['xmin']) /  int(target['annotation']['size']['width']) ) * 224
    xmax = ( int(target['annotation']['object'][0]['bndbox']['xmax']) /  int(target['annotation']['size']['width']) ) * 224

    ymin = ( int(target['annotation']['object'][0]['bndbox']['ymin']) /  int(target['annotation']['size']['height']) ) * 224
    ymax = ( int(target['annotation']['object'][0]['bndbox']['ymax']) /  int(target['annotation']['size']['height']) ) * 224

    width = xmax-xmin
    height = ymax-ymin
    
    return img, [xmin, xmax, ymin, ymax]

import math
import random
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from collections import namedtuple
from itertools import count
from PIL import Image
import torch.optim as optim
import cv2 as cv
import sys
from torch.autograd import Variable
import traceback

import sys
import os

Transition = namedtuple('Transition',
                        ('state', 'action', 'next_state', 'reward'))


transform = transforms.Compose([
            transforms.ToPILImage(),
            transforms.Resize((224,224)),
            transforms.ToTensor(),
           # transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))  #  numbers here need to be adjusted in future
])

use_cuda = True
FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor
LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor
ByteTensor = torch.cuda.ByteTensor if use_cuda else torch.ByteTensor
Tensor = FloatTensor
if use_cuda:
    criterion = nn.MSELoss().cuda()   
else:
    criterion = nn.MSELoss()
class ReplayMemory(object):

    def __init__(self, capacity):
        self.capacity = capacity
        self.memory = []
        self.position = 0

    def push(self, *args):
        """Saves a transition."""
        if len(self.memory) < self.capacity:
            self.memory.append(None)
        self.memory[self.position] = Transition(*args)
        self.position = (self.position + 1) % self.capacity

    def sample(self, batch_size):
        return random.sample(self.memory, batch_size)

    def __len__(self):
        return len(self.memory)


class Agent():
    def __init__(self, classe, alpha=0.2, nu=0.3, threshold=0.5, num_episodes=15, load=False ):
        self.BATCH_SIZE = 32
        self.GAMMA = 0.999
        self.EPS = 1
        self.TARGET_UPDATE = 1
        self.save_path = SAVE_MODEL_PATH
        screen_height, screen_width = 224, 224
        self.n_actions = 9
        self.classe = classe

        self.feature_extractor = FeatureExtractor()
        if not load:
            self.policy_net = DQN(screen_height, screen_width, self.n_actions)
        else:
            self.policy_net = self.load_network()
        self.target_net = DQN(screen_height, screen_width, self.n_actions)
        self.target_net.load_state_dict(self.policy_net.state_dict())
        self.target_net.eval()
        
        if use_cuda:
          self.feature_extractor = self.feature_extractor.cuda()
          self.target_net = self.target_net.cuda()
          self.policy_net = self.policy_net.cuda()
        
        self.optimizer = optim.Adam(self.policy_net.parameters(),lr=1e-6)
        self.memory = ReplayMemory(10000)
        self.steps_done = 0
        self.episode_durations = []
        
        self.alpha = alpha # €[0, 1]  Scaling factor
        self.nu = nu # Reward of Trigger
        self.threshold = threshold
        self.actions_history = []
        self.num_episodes = num_episodes
        self.actions_history += [[100]*9]*20

    def save_network(self):
        torch.save(self.policy_net, self.save_path+"_"+self.classe)
        print('Saved')

    def load_network(self):
        if not use_cuda:
            return torch.load(self.save_path+"_"+self.classe, map_location=torch.device('cpu'))
        return torch.load(self.save_path)

    def intersection_over_union(self, box1, box2):
        # ymin, xmin, ymax, xmax = box
        # x_min, x_max, y_min, y_max 
        x11, x21, y11, y21 = box1
        x12, x22, y12, y22 = box2
        
        """        
        y11, x11, y21, x21 = box1
        y12, x12, y22, x22 = box2
        """

        yi1 = max(y11, y12)
        xi1 = max(x11, x12)
        yi2 = min(y21, y22)
        xi2 = min(x21, x22)
        inter_area = max(((xi2 - xi1) * (yi2 - yi1)), 0)
        # Calculate the Union area by using Formula: Union(A,B) = A + B - Inter(A,B)
        box1_area = (x21 - x11) * (y21 - y11)
        box2_area = (x22 - x12) * (y22 - y12)
        union_area = box1_area + box2_area - inter_area
        # compute the IoU
        iou = inter_area / union_area
        return iou

    def compute_reward(self, actual_state, previous_state, ground_truth):
        res = self.intersection_over_union(actual_state, ground_truth) - self.intersection_over_union(previous_state, ground_truth)
        if res <= 0:
            return -1
        return 1
      
    def rewrap(self, coord):
        return min(max(coord,0), 224)
      
    def compute_trigger_reward(self, actual_state, ground_truth):
        res = self.intersection_over_union(actual_state, ground_truth)
        if res>self.threshold:
            return -self.nu
        return self.nu

    def get_best_next_action(self, actions, ground_truth):
        max_reward = -99
        best_action = -1
        actual_equivalent_coord = self.calculate_position_box(actions)
        for i in range(0, 9):
            copy_actions = actions.copy()
            copy_actions.append(i)
            new_equivalent_coord = self.calculate_position_box(copy_actions)
            if i!=0:
                reward = self.compute_reward(new_equivalent_coord, actual_equivalent_coord, ground_truth)
            else:
                reward = self.compute_trigger_reward(new_equivalent_coord,  ground_truth)
            if reward>max_reward:
                max_reward = reward
                best_action = i

        return best_action

    def do_action(self, image, action, xmin=0, xmax=224, ymin=0, ymax=224):      
        r = action
        alpha_h = self.alpha * (  ymax - ymin )
        alpha_w = self.alpha * (  xmax - xmin )
        #print(r)
        if r == 0:
            pass
        if r == 1:
            xmin += alpha_w
        if r == 2:
            xmax -= alpha_w
        if r == 3:
            ymin += alpha_h
        if r == 4:
            ymax -= alpha_h
        if r == 5:
            xmin -= alpha_w
        if r == 6:
            xmax += alpha_w
        if r == 7:
            ymin -= alpha_h
        if r == 8:
            ymax += alpha_h
        return [self.rewrap(xmin), self.rewrap(xmax), self.rewrap(ymin), self.rewrap(ymax)]

    def select_action(self, state, actions, ground_truth):
        sample = random.random()
        eps_threshold = self.EPS
        self.steps_done += 1
        if sample > eps_threshold:
            with torch.no_grad():
                if use_cuda:
                    inpu = Variable(state).cuda()
                else:
                    inpu = Variable(state)
                qval = self.policy_net(inpu)
                _, predicted = torch.max(qval.data,1)
                action = predicted[0] # + 1
                try:
                  return action.cpu().numpy()[0]
                except:
                  return action.cpu().numpy()
        else:
          #return np.random.randint(0,9)
            return self.get_best_next_action(actions, ground_truth)

    def optimize_model(self):
        if len(self.memory) < self.BATCH_SIZE:
            return
        transitions = self.memory.sample(self.BATCH_SIZE)
        batch = Transition(*zip(*transitions))

        non_final_mask = torch.Tensor(tuple(map(lambda s: s is not None, batch.next_state))).bool()
        next_states = [s for s in batch.next_state if s is not None]
        non_final_next_states = Variable(torch.cat(next_states), 
                                         volatile=True).type(Tensor)
        
        state_batch = Variable(torch.cat(batch.state)).type(Tensor)
        if use_cuda:
            state_batch = state_batch.cuda()
        action_batch = Variable(torch.LongTensor(batch.action).view(-1,1)).type(LongTensor)
        reward_batch = Variable(torch.FloatTensor(batch.reward).view(-1,1)).type(Tensor)

        # Compute Q(s_t, a) - the model computes Q(s_t), then we select the
        # columns of actions taken
        state_action_values = self.policy_net(state_batch).gather(1, action_batch)

        # Compute V(s_{t+1}) for all next states.
        next_state_values = Variable(torch.zeros(self.BATCH_SIZE, 1).type(Tensor)) 

        if use_cuda:
            non_final_next_states = non_final_next_states.cuda()
        d = self.target_net(non_final_next_states) # Eventually replace with policy_net
        next_state_values[non_final_mask] = d.max(1)[0].view(-1,1)

        # Now, we don't want to mess up the loss with a volatile flag, so let's
        # clear it. After this, we'll just end up with a Variable that has
        # requires_grad=False
        next_state_values.volatile = False

        # Compute the expected Q values
        expected_state_action_values = (next_state_values * self.GAMMA) + reward_batch

        # Compute  loss
        loss = criterion(state_action_values, expected_state_action_values)

        # Optimize the model
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    
    def compose_state(self, image, dtype=FloatTensor):
      image_feature = self.get_features(image, dtype)
      image_feature = image_feature.view(1,-1)
      history_flatten = self.actions_history.view(1,-1).type(dtype)
      state = torch.cat((image_feature, history_flatten), 1)
      return state
    
    def get_features(self, image, dtype=FloatTensor):
      global transform
      #image = transform(image)
      image = image.view(1,*image.shape)
      image = Variable(image).type(dtype)
      if use_cuda:
          image = image.cuda()
      feature = self.feature_extractor(image)
      return feature.data

    
    def update_history(self, action):
      action_vector = torch.zeros(9)
      action_vector[action] = 1
      size_history_vector = len(torch.nonzero(self.actions_history))
      if size_history_vector < 9:
          self.actions_history[size_history_vector][action] = 1
      else:
          for i in range(8,0,-1):
              self.actions_history[i][:] = self.actions_history[i-1][:]
          self.actions_history[0][:] = action_vector[:] 
      return self.actions_history

    def calculate_position_box(self, actions, xmin=0, xmax=224, ymin=0, ymax=224):
      alpha_h = self.alpha * (  ymax - ymin )
      alpha_w = self.alpha * (  xmax - xmin )
      real_x_min, real_x_max, real_y_min, real_y_max = 0, 224, 0, 224
      for r in actions:
        if r == 1:
          real_x_min += alpha_w
        if r == 2:
          real_x_max -= alpha_w
        if r == 3:
          real_y_min += alpha_h
        if r == 4:
          real_y_max -= alpha_h
        if r == 5:
          real_x_min -= alpha_w
        if r == 6:
          real_x_max += alpha_w
        if r == 7:
          real_y_min -= alpha_h
        if r == 8:
          real_y_max += alpha_h
        real_x_min, real_x_max, real_y_min, real_y_max = int(self.rewrap(real_x_min)), int(self.rewrap(real_x_max)), int(self.rewrap(real_y_min)), int(self.rewrap(real_y_max))
      return [real_x_min, real_x_max, real_y_min, real_y_max]
    
    def train(self, train_loader):
        xmin = 0
        xmax = 224
        ymin = 0
        ymax = 224

        skipped = 0
        treated = 0
        for i_episode in range(self.num_episodes):
            
            for index in  range(len(train_loader)):
                try:
                    #clear_output()
                    os.system('cls')
                    print("Class : "+str(self.classe))
                    print("EPS = "+str(self.EPS))
                    print("\n\nEpisode : ("+str(i_episode)+"/"+str(self.num_episodes)+")")
                    print("Image ("+str(index)+"/"+str(len(train_loader))+")")
                    print("Treated "+str((treated/(treated+skipped+1))*100     )+"%")
                    image, [oxmin, oxmax, oymin, oymax] = extract(index, train_loader)
                    #image = image.transpose(0, 2).transpose(0, 1)

                    labels = [oxmin, oxmax, oymin, oymax]
                    actual_coordinates = [xmin, xmax, ymin, ymax]
                    original_image = image.clone()
                    ground_truth = labels
            
                    all_actions = []
            
                    # Initialize the environment and state
                    self.actions_history = torch.ones((9,9))
                    state = self.compose_state(image)
                    original_coordinates = [xmin, xmax, ymin, ymax]
                    new_image = image
                    done = False
                    t = 0
                    actual_coordinates = original_coordinates
                    new_coordinates = original_coordinates
                    treated += 1
                    while not done:
                        action = self.select_action(state, all_actions, ground_truth)
                        all_actions.append(action)
                        if action == 0:
                            next_state = None
                            new_equivalent_coord = self.calculate_position_box(all_actions)
                            reward = self.compute_trigger_reward(new_equivalent_coord,  ground_truth)
                            done = True

                        else:
                            self.actions_history = self.update_history(action)
                            new_x_min, new_x_max, new_y_min, new_y_max = self.do_action(image, action,  xmin, xmax, ymin, ymax)
                            
                            new_coordinates = [new_x_min, new_x_max, new_y_min, new_y_max]
                            new_equivalent_coord = self.calculate_position_box(all_actions)
                            actual_equivalent_coord = self.calculate_position_box(all_actions[:-2])
                            
                            
                            new_image = original_image[:, int(new_equivalent_coord[2]):int(new_equivalent_coord[3]), int(new_equivalent_coord[0]):int(new_equivalent_coord[1])]
                            new_image = transform(new_image)
                            
                            """
                            show_new_bdbox(original_image, ground_truth, color='r')
                            show_new_bdbox(original_image, new_equivalent_coord, color='b')
                            
                            
                            fig,ax = plt.subplots(1)
                            ax.imshow(new_image.transpose(0, 2).transpose(0, 1))
                            plt.show()
                            """
                            
                            next_state = self.compose_state(new_image)
                            reward = self.compute_reward(new_equivalent_coord, actual_equivalent_coord, ground_truth)
                            xmin, xmax, ymin, ymax = new_x_min, new_x_max, new_y_min, new_y_max
                        
                        
                        self.memory.push(state, int(action), next_state, reward)

                        # Move to the next state
                        state = next_state
                        actual_coordinates = new_coordinates
                        image = new_image
                        # Perform one step of the optimization (on the target network)
                        self.optimize_model()
                        
                except ValueError:
                    skipped += 1
            if i_episode % self.TARGET_UPDATE == 0:
                self.target_net.load_state_dict(self.policy_net.state_dict())
            if i_episode<5:
                self.EPS -= 0.18
            self.save_network()
            

            print('Complete')

class FeatureExtractor(nn.Module):
  def __init__(self):
    super(FeatureExtractor, self).__init__() # recopier toute la partie convolutionnelle
    vgg16 = torchvision.models.vgg16(pretrained=True)
    vgg16.eval() # to not do dropout
    self.features = nn.Sequential( *list(vgg16.features.children()))
    # understand feature and classifier: https://www.kaggle.com/carloalbertobarbano/vgg16-transfer-learning-pytorch
    # garder une partie du classifieur, -2 pour s'arrêter à relu7
    self.classifier = nn.Sequential(*list(vgg16.classifier.children())[:-2])
  def forward(self, x):
    x = self.features(x)
    x = x.view(x.size(0), -1)
    x = self.classifier(x)
    return x
  
class DQN(nn.Module):
    def __init__(self, h, w, outputs):
        super(DQN, self).__init__()
        self.classifier = nn.Sequential(
            nn.Linear( in_features= 81 + 4096, out_features=1024),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear( in_features= 1024, out_features=1024),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear( in_features= 1024, out_features=9)
        )
    # Called with either one element to determine next action, or a batch
    # during optimization. Returns tensor([[left0exp,right0exp]...]).
    def forward(self, x):
        return self.classifier(x)

import warnings
train_loader2012, val_loader2012 = read_voc_dataset(download=LOAD, year='2012')
train_loader2007, val_loader2007 = read_voc_dataset(download=LOAD, year='2007')

"""
Nbr of training elements per class in VOC2007 + VOC2012
cat : 648 elements.
bird : 553 elements.       
motorbike : 304 elements.  
diningtable : 188 elements.
train : 369 elements.      
tvmonitor : 290 elements.  
bus : 268 elements.        
horse : 310 elements.      
car : 659 elements.
pottedplant : 202 elements.
person : 1301 elements.
chair : 379 elements.
boat : 289 elements.
bottle : 258 elements.
bicycle : 303 elements.
dog : 750 elements.
aeroplane : 432 elements.
cow : 210 elements.
sheep : 208 elements.
sofa : 297 elements.
"""

classes = ['cat', 'bird', 'motorbike', 'diningtable', 'train', 'tvmonitor', 'bus', 'horse', 'car', 'pottedplant', 'person', 'chair', 'boat', 'bottle', 'bicycle', 'dog', 'aeroplane', 'cow', 'sheep', 'sofa']
def sort_class_extract(datasets):    
    datasets_per_class = {}
    for j in classes:
        datasets_per_class[j] = []

    for dataset in datasets:
        for i in dataset:
            img, target = i
            classe = target['annotation']['object'][0]["name"]
            datasets_per_class[classe].append(i)
           
    return datasets_per_class

agents_per_class = {}
datasets_per_class = sort_class_extract([train_loader2007, train_loader2012])
for key in classes:
    agents_per_class[key] = Agent(key, alpha=0.02, num_episodes=25, load=False)
    agents_per_class[key].train(datasets_per_class[key])
